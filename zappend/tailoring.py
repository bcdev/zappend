# Copyright Â© 2024 Norman Fomferra
# Permissions are hereby granted under the terms of the MIT License:
# https://opensource.org/licenses/MIT.

import dask.array
import numpy as np
import xarray as xr

from .context import Context
from .log import logger
from .metadata import DatasetMetadata


def tailor_target_dataset(ctx: Context, slice_ds: xr.Dataset) -> xr.Dataset:
    target_metadata = ctx.target_metadata
    attrs_update_mode = ctx.attrs_update_mode
    attrs = ctx.attrs

    target_ds = _strip_dataset(slice_ds, target_metadata)
    target_ds = _complete_dataset(target_ds, target_metadata)

    # TODO: use ctx.attrs_update_mode to set initial dataset attributes

    # Set initial dataset attributes
    if attrs_update_mode == "ignore":
        # Ignore attributes from slice dataset
        target_ds.attrs = {}
    else:
        target_ds.attrs = target_metadata.attrs
    if attrs:
        # Always update by configured attributes
        target_ds.attrs.update(attrs)

    # Set variable encoding and attributes
    for var_name, var_metadata in target_metadata.variables.items():
        variable = target_ds.variables[var_name]
        variable.encoding = var_metadata.encoding.to_dict()
        variable.attrs = var_metadata.attrs

    return target_ds


def tailor_slice_dataset(ctx: Context, slice_ds: xr.Dataset) -> xr.Dataset:
    target_metadata = ctx.target_metadata
    append_dim = ctx.append_dim
    attrs_update_mode = ctx.attrs_update_mode
    attrs = ctx.attrs

    slice_ds = _strip_dataset(slice_ds, target_metadata)
    slice_ds = _complete_dataset(slice_ds, target_metadata)

    const_variables = [
        k for k, v in slice_ds.variables.items() if append_dim not in v.dims
    ]
    if const_variables:
        # Strip variables that do not have append_dim
        # as dimension, e.g., "x", "y", "crs", ...
        slice_ds = slice_ds.drop_vars(const_variables)

    # https://github.com/bcdev/zappend/issues/56
    # slice_dataset.to_zarr(store, mode="a", ...) will replace
    # global attributes.
    # Therefore, we must take care how slice dataset attributes
    # are updated.
    # If attrs_update_op is "replace", we just keep slice attributes
    if attrs_update_mode == "keep":
        # Keep existing attributes
        slice_ds.attrs = target_metadata.attrs
    elif attrs_update_mode == "update":
        # Update from last slice dataset
        slice_ds.attrs = target_metadata.attrs | slice_ds.attrs
    elif attrs_update_mode == "ignore":
        # Ignore attributes from slice dataset
        slice_ds.attrs = {}
    if attrs:
        # Always update by configured attributes
        slice_ds.attrs.update(attrs)

    # Remove any encoding and attributes from slice,
    # since both are prescribed by target
    for variable in slice_ds.variables.values():
        variable.encoding = {}
        variable.attrs = {}
    return slice_ds


def _strip_dataset(dataset: xr.Dataset, target_metadata: DatasetMetadata) -> xr.Dataset:
    drop_var_names = set(map(str, dataset.variables.keys())) - set(
        target_metadata.variables.keys()
    )
    return dataset.drop_vars(drop_var_names)


def _complete_dataset(
    dataset: xr.Dataset, target_metadata: DatasetMetadata
) -> xr.Dataset:
    for var_name, var_metadata in target_metadata.variables.items():
        var = dataset.variables.get(var_name)
        if var is not None:
            continue
        logger.warning(
            f"Variable {var_name!r} not found in slice dataset;" f" creating it."
        )
        encoding = var_metadata.encoding.to_dict()
        chunks = encoding.get("chunks")
        if chunks is None:
            chunks = var_metadata.shape
        if encoding.get("_FillValue") is not None:
            # Since we have a defined fill value, the decoded in-memory
            # variable uses NaN where fill value will be stored.
            # This ia also what xarray does if decode_cf=True.
            memory_dtype = np.dtype("float64")
            memory_fill_value = float("NaN")
        else:
            # Fill value is not defined, so we use the data type
            # defined in the encoding, if any and fill memory with zeros.
            memory_dtype = encoding.get("dtype", np.dtype("float64"))
            memory_fill_value = 0
        var = xr.DataArray(
            dask.array.full(
                var_metadata.shape,
                memory_fill_value,
                chunks=chunks,
                dtype=np.dtype(memory_dtype),
            ),
            dims=var_metadata.dims,
        )
        dataset[var_name] = var
    return dataset
