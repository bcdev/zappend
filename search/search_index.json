{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"The zappend Tool","text":"<p><code>zappend</code> is a tool written in Python that is used for creating and updating  a Zarr dataset from smaller dataset slices.</p>"},{"location":"#motivation","title":"Motivation","text":"<p>The objective of <code>zappend</code> is to address recurring memory issues when  generating large geospatial datacubes using the  Zarr format by subsequently concatenating data slices along an append dimension, usually <code>time</code>. Each append step is atomic,  that is, the append operation is a transaction that can be rolled back,  in case the append operation fails. This ensures integrity of the target  data cube. </p>"},{"location":"#features","title":"Features","text":"<p>The <code>zappend</code> tool provides the following features</p> <ul> <li>Transaction-based dataset appends: On failure during an append step,    the transaction is rolled back, so that the target dataset remains valid and    preserves its integrity.</li> <li>Filesystem transparency: The target dataset may be generated and updated in    any writable filesystems supported by the    fsspec package.    The same holds for the slice datasets to be appended.</li> <li>Slices polling: The tool can be configured to wait for slice datasets to    become available. </li> <li>CLI and Python API: The tool can be used in a shell using the <code>zappend</code>   command or from Python. When used from Python using the    <code>zappend()</code> function, slice datasets can be passed as local file paths,    URIs, or as in-memory datasets of type    xarray.Dataset.   Users can implement their own slice sources and provide them to the that provide    slice dataset objects and are disposed after each slice has been processed.</li> </ul>"},{"location":"#how-it-works","title":"How It Works","text":"<p>At its core, <code>zappend</code> calls the  to_zarr() method of  xarray.Dataset  for each dataset slice it receives and either creates the target dataset if it does not  exist yet or updates it with the current slice, if it already exists.</p> <p>If there is no target dataset yet, <code>zappend</code> does the following:</p> <ul> <li>create target metadata from configuration and slice dataset;</li> <li>tailor slice according to target metadata and configuration;</li> <li>set encoding and attributes in slice according to target metadata;</li> <li>write target from slice.</li> </ul> <p>If target dataset exists, then <code>zappend</code> will:</p> <ul> <li>create target metadata from configuration and target dataset;</li> <li>create slice metadata from configuration and slice dataset;</li> <li>verify target and slice metadata are compatible;</li> <li>tailor slice according to target metadata and configuration;</li> <li>remove encoding and attributes from slice;</li> <li>update target from slice.</li> </ul>"},{"location":"about/","title":"About zappend","text":""},{"location":"about/#change-log","title":"Change Log","text":"<p>You can find the complete <code>zappend</code> changelog  here. </p>"},{"location":"about/#reporting","title":"Reporting","text":"<p>If you have suggestions, ideas, feature requests, or if you have identified a malfunction or error, then please  post an issue. </p>"},{"location":"about/#contributions","title":"Contributions","text":"<p>The <code>zappend</code> project welcomes contributions of any form as long as you respect our  code of conduct and follow our  contribution guide.</p> <p>If you'd like to submit code or documentation changes, we ask you to provide a  pull request (PR)  here.  For code and configuration changes, your PR must be linked to a  corresponding issue. </p>"},{"location":"about/#development","title":"Development","text":"<p>Setup development environment:</p> <pre><code>pip install -r requirements.txt\npip install -r requirements-dev.txt\npip install -r requirements-docs.txt\n</code></pre>"},{"location":"about/#testing-and-coverage","title":"Testing and Coverage","text":"<p><code>zappend</code> uses pytest for unit-level testing  and code coverage analysis.</p> <pre><code>pytest --cov=zappend tests\n</code></pre>"},{"location":"about/#code-style","title":"Code Style","text":"<p><code>zappend</code> source code is formatted using the black tool.</p> <pre><code>black zappend\n</code></pre>"},{"location":"about/#documentation","title":"Documentation","text":"<p><code>zappend</code> documentation is build using the mkdocs tool.</p> <pre><code>pip install -r requirements-doc.txt\n\nmkdocs build\n</code></pre>"},{"location":"about/#original-requirements","title":"Original Requirements","text":""},{"location":"about/#core-requirements","title":"Core Requirements","text":"<ul> <li>Create a target Zarr dataset by appending Zarr dataset slices along a    given append dimension, usually <code>time</code>.   </li> <li>The tool takes care of modifying the target dataset using the slices,   but doesn't care how the slice datasets are created.</li> <li>Slice datasets may be given as URIs with storage options or as    in-memory datasets of type    xarray.Dataset   or    xcube.core.mldataset.MultiLevelDataset.</li> <li>Target and slices are allowed to live in different filesystems.</li> <li>The tool is configurable. The configuration defines </li> <li>the append dimension;</li> <li>optional target encoding for all or individual target variables;</li> <li>the target path into the target filesystem;</li> <li>optional target storage options;</li> <li>optional slice storage options.</li> <li>The target chunking of the append dimension equals the size of the append    dimension in each slice and vice versa. </li> <li>The target encoding should allow for specifying the target storage chunking,    data type, and compression. </li> <li>The target encoding should also allow for packing floating point data into    integer data with fewer bits using scaling factor and offset.</li> <li>Detect coordinate variables and allow them to stay un-chunked.   This is important for coordinate variables containing or corresponding    to the append-dimension.</li> <li>If the target does not exist, it will be created from a copy of the first    slice. This first slice will specify any not-yet-configured properties   of the target dataset, e.g., the append dimension chunking.</li> <li>If the target exists, the slice will be appended. Check if the slice to be    appended is last. If not, refuse to append (alternative: insert but this is    probably difficult or error prone).</li> <li>Slices are appended in the order they are provided.</li> <li>If a slice is not yet available, wait and retry until it </li> <li>exists, and</li> <li>is complete.</li> <li>Check for each slice that it is valid. A valid slice</li> <li>is self-consistent, </li> <li>has the same structure as target, and</li> <li>has an append dimension whose size is equal to the target chunking of     this dimension.</li> <li>Before appending a slice, lock the target so that another tool invocation    can recognize it, e.g., write a lock file.</li> <li>If the target is locked, either wait until it becomes available or exit    with an error. The behaviour is controlled by a tool option.</li> <li>After successfully appending a slice, remove the lock from the target.</li> <li>Appending a slice shall be an atomic operation to ensure target dataset    integrity. That is, in case a former append step failed, a rollback must   be performed to restore the last valid state of the target. Rolling back   shall take place after an append failed, or before a new slice is appended,   or to sanitize a target to make it usable again. Rolling back shall    include restoring all changed files, removing all added files,    and removing any locks. </li> <li>The tool shall allow for continuing appending slices at the point   it failed.</li> <li>The tool shall offer a CLI and a Python API.</li> <li>Using the CLI, slices are given as a variadic argument that provides the      file paths into the slice filesystem.</li> <li>Using the Python API, it shall be possible to provide the slices by      specifying a function that generates the slice datasets and an     iterable providing the arguments for the function.     This is similar how the Python <code>map()</code> built-in works.</li> </ul>"},{"location":"about/#further-ideas","title":"Further Ideas","text":"<ul> <li>Allow for inserting and deleting slices.</li> <li>Allow specifying a constant delta between coordinates of the append dimension.</li> <li>Verify append dimension coordinates increase or decrease monotonically. </li> <li>Verify coordinate deltas of append dimension to be constant. </li> <li>Integration with xcube:</li> <li>Add xcube server API: Add endpoint to xcube server that works similar      to the CLI and also uses a similar request parameters.</li> <li>Use it in xcube data stores for the <code>write_data()</code> method, as a parameter      to enforce sequential writing of Zarr datasets as a robust option when a      plain write fails.</li> </ul>"},{"location":"about/#license","title":"License","text":"<p><code>zappend</code> is made available under the terms and conditions of the MIT License:</p> <p>Copyright (c) 2023 Brockmann Consult Development</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"api/","title":"Python API reference","text":"<p>All described objects can be imported from the <code>zappend.api</code> module.</p>"},{"location":"api/#function-zappend","title":"Function <code>zappend</code>","text":"<p>Create or update a Zarr dataset from dataset slices.</p> <p>Parameters:</p> Name Type Description Default <code>slices</code> <code>Iterable[SliceObj | SliceFactory]</code> <p>An iterable that yields slice objects. A slice object is either a <code>str</code>, <code>xarray.Dataset</code>, <code>SliceSource</code> or a factory function that returns a slice object. If <code>str</code> is used, it is interpreted as local dataset path or dataset URI. If a URI is used, protocol-specific parameters apply, given by configuration parameter <code>slice_storage_options</code>.</p> required <code>config</code> <code>ConfigLike</code> <p>Processor configuration. May be a file path or URI, a <code>dict</code>, <code>None</code>, or a sequence of the aforementioned. If a sequence is used, subsequent configurations are incremental to the previous ones.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional configuration parameters. Can be used to pass or override configuration values in config.</p> <code>{}</code>"},{"location":"api/#class-slicesource","title":"Class <code>SliceSource</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Represents a source for a slice dataset. Instances of this class are supposed to be used as context managers. The context manager provides the dataset instance by calling the get_dataset() method. When the context manager exits, the dispose() method is called.</p> <p>You may implement your own slice source class and define a slice source factory function that creates instances of your slice source. Such functions can be passed input to the zappend() function, usually in the form of a closure to capture slice-specific information.</p> <p>Parameters:</p> Name Type Description Default <code>ctx</code> <code>Context</code> <p>The processing context.</p> required"},{"location":"api/#zappend.slice.abc.SliceSource.ctx","title":"<code>ctx: Context</code>  <code>property</code>","text":"<p>The processing context passed to the constructor.</p>"},{"location":"api/#zappend.slice.abc.SliceSource.dispose","title":"<code>dispose()</code>","text":"<p>Dispose this slice source. This should include cleaning up of used resources.</p> <p>This method is not intended to be called directly. Instead, instances of this class are context managers and should be used as such.</p>"},{"location":"api/#zappend.slice.abc.SliceSource.get_dataset","title":"<code>get_dataset()</code>  <code>abstractmethod</code>","text":"<p>Open this slice source and return the dataset instance.</p> <p>This method is not intended to be called directly. Instead, instances of this class are context managers and should be used as such.</p> <p>It should return a dataset that is compatible with target dataset:</p> <ul> <li>slice must have same fixed dimensions;</li> <li>append dimension must exist in slice.</li> </ul> <p>Returns:</p> Type Description <code>Dataset</code> <p>A slice dataset.</p>"},{"location":"api/#class-context","title":"Class <code>Context</code>","text":"<p>Provides access to configuration values and values derived from it.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>A validated configuration.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>target_dir</code> is missing in the configuration.</p>"},{"location":"api/#zappend.context.Context.append_dim_name","title":"<code>append_dim_name: str</code>  <code>property</code>","text":"<p>The configured append dimension.</p>"},{"location":"api/#zappend.context.Context.disable_rollback","title":"<code>disable_rollback: bool</code>  <code>property</code>","text":"<p>Whether to disable transaction rollbacks.</p>"},{"location":"api/#zappend.context.Context.dry_run","title":"<code>dry_run: bool</code>  <code>property</code>","text":"<p>Whether to run in dry mode.</p>"},{"location":"api/#zappend.context.Context.persist_mem_slices","title":"<code>persist_mem_slices: bool</code>  <code>property</code>","text":"<p>Whether to persist in-memory slice datasets.</p>"},{"location":"api/#zappend.context.Context.slice_engine","title":"<code>slice_engine: str | None</code>  <code>property</code>","text":"<p>The configured slice engine to be used if a slice object is not a Zarr. If defined, it will be passed to the <code>xarray.open_dataset()</code> function.</p>"},{"location":"api/#zappend.context.Context.slice_polling","title":"<code>slice_polling: tuple[float, float] | tuple[None, None]</code>  <code>property</code>","text":"<p>The configured slice dataset polling. If slice polling is enabled, returns tuple (interval, timeout) in seconds, otherwise, return (None, None).</p>"},{"location":"api/#zappend.context.Context.slice_storage_options","title":"<code>slice_storage_options: dict[str, Any] | None</code>  <code>property</code>","text":"<p>The configured slice storage options to be used if a slice object is a Zarr.</p>"},{"location":"api/#zappend.context.Context.target_dir","title":"<code>target_dir: FileObj</code>  <code>property</code>","text":"<p>The configured target directory.</p>"},{"location":"api/#zappend.context.Context.target_metadata","title":"<code>target_metadata: DatasetMetadata | None</code>  <code>property</code> <code>writable</code>","text":"<p>The metadata for the target dataset. May be <code>None</code> while the target dataset hasn't been created yet. Will be set, once the target dataset has been created from the first slice dataset.</p>"},{"location":"api/#zappend.context.Context.temp_dir","title":"<code>temp_dir: FileObj</code>  <code>property</code>","text":"<p>The configured directory used for temporary files such as rollback data.</p>"},{"location":"api/#zappend.context.Context.zarr_version","title":"<code>zarr_version: int</code>  <code>property</code>","text":"<p>The configured Zarr version for the target dataset.</p>"},{"location":"api/#zappend.context.Context.get_dataset_metadata","title":"<code>get_dataset_metadata(dataset)</code>","text":"<p>Get the dataset metadata from configuration and the given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The dataset</p> required <p>Returns:</p> Type Description <code>DatasetMetadata</code> <p>The dataset metadata</p>"},{"location":"api/#class-fileobj","title":"Class <code>FileObj</code>","text":"<p>An object that represents a file or directory in some filesystem.</p> <p>Parameters:</p> Name Type Description Default <code>uri</code> <code>str</code> <p>The file or directory URI</p> required <code>storage_options</code> <code>dict[str, Any] | None</code> <p>Optional storage options specific to the protocol of the URI</p> <code>None</code> <code>fs</code> <code>AbstractFileSystem | None</code> <p>Optional fsspec filesystem instance. Use with care, the filesystem must be consistent with uri and storage_options. For internal use only.</p> <code>None</code> <code>path</code> <code>str | None</code> <p>The path info the filesystem fs. Use with care, the path must be consistent with uri. For internal use only.</p> <code>None</code>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.filename","title":"<code>filename: str</code>  <code>property</code>","text":"<p>The filename part of the URI.</p>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.fs","title":"<code>fs: fsspec.AbstractFileSystem</code>  <code>property</code>","text":"<p>The filesystem.</p>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.parent","title":"<code>parent: FileObj</code>  <code>property</code>","text":"<p>The parent file object.</p>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.path","title":"<code>path: str</code>  <code>property</code>","text":"<p>The path of the file or directory into the filesystem.</p>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.storage_options","title":"<code>storage_options: dict[str, Any] | None</code>  <code>property</code>","text":"<p>Storage options for creating the filesystem object.</p>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.uri","title":"<code>uri: str</code>  <code>property</code>","text":"<p>The URI.</p>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.__truediv__","title":"<code>__truediv__(rel_path)</code>","text":"<p>Overriden to call for_path(rel_path).</p> <p>Parameters:</p> Name Type Description Default <code>rel_path</code> <code>str</code> <p>Relative path to append.</p> required"},{"location":"api/#zappend.fsutil.fileobj.FileObj.close","title":"<code>close()</code>","text":"<p>Close the filesystem used by this file object.</p>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.delete","title":"<code>delete(recursive=False)</code>","text":"<p>Delete the file or directory represented by this file object.</p> <p>Parameters:</p> Name Type Description Default <code>recursive</code> <code>bool</code> <p>Set to <code>True</code> to delete a non-empty directory.</p> <code>False</code>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.exists","title":"<code>exists()</code>","text":"<p>Check if the file or directory represented by this file object exists.</p>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.for_path","title":"<code>for_path(rel_path)</code>","text":"<p>Gets a new file object for the given relative path.</p> <p>Parameters:</p> Name Type Description Default <code>rel_path</code> <code>str</code> <p>Relative path to append.</p> required <p>Returns:</p> Type Description <code>FileObj</code> <p>A new file object</p>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.mkdir","title":"<code>mkdir()</code>","text":"<p>Create the directory represented by this file object.</p>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.read","title":"<code>read(mode='rb')</code>","text":"<p>Read the contents of the file represented by this file object.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>Literal['rb'] | Literal['r']</code> <p>Read mode, must be \"rb\" or \"r\"</p> <code>'rb'</code> <p>Returns:</p> Type Description <code>bytes | str</code> <p>The contents of the file either as <code>bytes</code> if mode is \"rb\" or as <code>str</code></p> <code>bytes | str</code> <p>if mode is \"r\".</p>"},{"location":"api/#zappend.fsutil.fileobj.FileObj.write","title":"<code>write(data, mode=None)</code>","text":"<p>Write the contents of the file represented by this file object.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str | bytes</code> <p>The data to write.</p> required <code>mode</code> <code>Literal['wb'] | Literal['w'] | Literal['ab'] | Literal['a'] | None</code> <p>Write mode, must be \"wb\", \"w\", \"ab\", or \"a\".</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>The number of bytes written.</p>"},{"location":"api/#types","title":"Types","text":""},{"location":"api/#zappend.slice.common.SliceObj","title":"<code>zappend.slice.common.SliceObj = str | FileObj | xr.Dataset | SliceSource</code>  <code>module-attribute</code>","text":"<p>The possible types that can represent a slice dataset.</p>"},{"location":"api/#zappend.slice.common.SliceFactory","title":"<code>zappend.slice.common.SliceFactory = Callable[[Context], SliceObj]</code>  <code>module-attribute</code>","text":"<p>Tne type for a factory function that returns a slice object for a given processing context.</p>"},{"location":"api/#zappend.config.ConfigItem","title":"<code>zappend.config.ConfigItem = FileObj | str | dict[str, Any]</code>  <code>module-attribute</code>","text":""},{"location":"api/#zappend.config.ConfigList","title":"<code>zappend.config.ConfigList = list[ConfigItem] | tuple[ConfigItem]</code>  <code>module-attribute</code>","text":""},{"location":"api/#zappend.config.ConfigLike","title":"<code>zappend.config.ConfigLike = ConfigItem | ConfigList | None</code>  <code>module-attribute</code>","text":"<p>The possible types used to represent processor configuration.</p>"},{"location":"cli/","title":"Command Line Interface Reference","text":"<pre><code>Usage: zappend [OPTIONS] [SLICES]...\n\n  Create or update a Zarr dataset TARGET from slice datasets SLICES.\n\nOptions:\n  -c, --config CONFIG    Configuration JSON or YAML file. If multiple are\n                         passed, subsequent configurations are incremental to\n                         the previous ones.\n  -t, --target TARGET    Target Zarr dataset path or URI. Overrides the\n                         'target_dir' configuration field.\n  --dry-run              Run the tool without creating, changing, or deleting\n                         any files.\n  --help-config json|md  Show configuration help and exit.\n  --help                 Show this message and exit.\n</code></pre>"},{"location":"config/","title":"Configuration","text":""},{"location":"config/#configuration-reference","title":"Configuration Reference","text":""},{"location":"config/#version","title":"<code>version</code>","text":"<p>Configuration schema version. Allows the schema to evolve while still preserving backwards compatibility. Its value is <code>1</code>.</p>"},{"location":"config/#target_dir","title":"<code>target_dir</code>","text":"<p>Type string. The URI or local path of the target Zarr dataset. Must be a directory.</p>"},{"location":"config/#target_storage_options","title":"<code>target_storage_options</code>","text":"<p>Type object. Options for the filesystem given by the URI of <code>target_dir</code>.</p>"},{"location":"config/#slice_engine","title":"<code>slice_engine</code>","text":"<p>Type string. The name of the engine to be used for opening contributing datasets. Refer to the <code>engine</code> argument of the function <code>xarray.open_dataset()</code>.</p>"},{"location":"config/#slice_storage_options","title":"<code>slice_storage_options</code>","text":"<p>Type object. Options for the filesystem given by the protocol of the URIs of contributing datasets.</p>"},{"location":"config/#slice_polling","title":"<code>slice_polling</code>","text":"<p>Defines how to poll for contributing datasets. Must be one of the following: * No polling, fail immediately if dataset is not available.   Its value is <code>false</code>. * Poll using default values.   Its value is <code>true</code>. * Type object.   Polling parameters.   The keys <code>interval</code>, <code>timeout</code> are required.</p> <ul> <li><code>interval</code>:     Type number.     Polling interval in seconds.     Defaults to <code>2</code>.</li> <li><code>timeout</code>:     Type number.     Polling timeout in seconds.     Defaults to <code>60</code>.</li> </ul>"},{"location":"config/#temp_dir","title":"<code>temp_dir</code>","text":"<p>Type string. The URI or local path of the directory that will be used to temporarily store rollback information.</p>"},{"location":"config/#temp_storage_options","title":"<code>temp_storage_options</code>","text":"<p>Type object. Options for the filesystem given by the protocol of <code>temp_dir</code>.</p>"},{"location":"config/#zarr_version","title":"<code>zarr_version</code>","text":"<p>The Zarr version to be used. Its value is <code>2</code>.</p>"},{"location":"config/#fixed_dims","title":"<code>fixed_dims</code>","text":"<p>Type object. Specifies the fixed dimensions of the target dataset. Keys are dimension names, values are dimension sizes.</p> <p>The object's values are of type integer.</p>"},{"location":"config/#append_dim","title":"<code>append_dim</code>","text":"<p>Type string. The name of the variadic append dimension. Defaults to <code>\"time\"</code>.</p>"},{"location":"config/#variables","title":"<code>variables</code>","text":"<p>Type object. Defines dimensions, encoding, and attributes for variables in the target dataset. Object property names refer to variable names. The special name <code>*</code> refers to all variables, which is useful for defining common values.</p> <p>The object's values are of type object. Variable metadata.</p> <ul> <li><code>dims</code>:   Type array.   The names of the variable's dimensions in the given order. Each dimension must exist in contributing datasets.</li> </ul> <p>The array's items are of type string. * <code>encoding</code>:   Type object.   Variable storage encoding. Settings given here overwrite the encoding settings of the first contributing dataset.</p> <ul> <li><code>dtype</code>:     Storage data type     Must be one of <code>\"int8\", \"uint8\", \"int16\", \"uint16\", \"int32\", \"uint32\", \"int64\", \"uint64\", \"float32\", \"float64\"</code>.</li> <li> <p><code>chunks</code>:     Storage chunking.     Must be one of the following:</p> <ul> <li>Type array.   Chunk sizes in the order of the dimensions.</li> </ul> <p>The array's items are of type integer. * Disable chunking.   Its value is <code>null</code>.   * <code>fill_value</code>: Storage fill value. Must be one of the following: * Type number.   A number of type and unit of the given storage <code>dtype</code>. * Not-a-number. Can be used only if storage <code>dtype</code> is <code>float32</code> or <code>float64</code>.   Its value is <code>\"NaN\"</code>. * No fill value.   Its value is <code>null</code>.   * <code>scale_factor</code>: Type number. Scale factor for computing the in-memory value: <code>memory_value = scale_factor * storage_value + add_offset</code>.   * <code>add_offset</code>: Type number. Add offset for computing the in-memory value: <code>memory_value = scale_factor * storage_value + add_offset</code>.   * <code>units</code>: Type string. Units of the storage data type if memory data type is date/time.   * <code>calendar</code>: Type string. The calendar to be used if memory data type is date/time.   * <code>compressor</code>: Type array | null. Compressor definition. Set to <code>null</code> to disable data compression. The key <code>id</code> is required.</p> <ul> <li><code>id</code>:   Type string.</li> </ul> </li> <li> <p><code>filters</code>:     Type array | null.     Filters. Set to <code>null</code> to not use filters.</p> <p>The array's items are of type object. Filter definition. The key <code>id</code> is required.</p> <ul> <li><code>id</code>:   Type string.</li> </ul> </li> <li> <p><code>attrs</code>:   Type object.   Arbitrary variable metadata attributes.</p> </li> </ul>"},{"location":"config/#included_variables","title":"<code>included_variables</code>","text":"<p>Type array. Specifies the names of variables to be included in the target dataset. Defaults to all variables found in the first contributing dataset.</p> <p>The array's items are of type string.</p>"},{"location":"config/#excluded_variables","title":"<code>excluded_variables</code>","text":"<p>Type array. Specifies the names of individual variables to be excluded  from all contributing datasets.</p> <p>The array's items are of type string.</p>"},{"location":"config/#persist_mem_slices","title":"<code>persist_mem_slices</code>","text":"<p>Type boolean. Persist in-memory slices and reopen from a temporary Zarr before appending them to the target dataset. This can prevent expensive re-computation of dask chunks at the cost of additional i/o. Defaults to <code>false</code>.</p>"},{"location":"config/#disable_rollback","title":"<code>disable_rollback</code>","text":"<p>Type boolean. Disable rolling back dataset changes on failure. Effectively disables transactional dataset modifications, so use this setting with care. Defaults to <code>false</code>.</p>"},{"location":"config/#dry_run","title":"<code>dry_run</code>","text":"<p>Type boolean. If 'true', log only what would have been done, but don't apply any changes. Defaults to <code>false</code>.</p>"},{"location":"config/#logging","title":"<code>logging</code>","text":"<p>Type object. Logging configuration. For details refer to the dictionary schema of the Python module <code>logging.config</code>. The key <code>version</code> is required.</p> <ul> <li><code>version</code>:   Logging schema version.   Its value is <code>1</code>.</li> <li><code>formatters</code>:   Type object.   Formatter definitions. Each key is a formatter id and each value is an object describing how to configure the corresponding formatter.</li> </ul> <p>The object's values are of type object.   Formatter configuration.</p> <ul> <li><code>format</code>:     Type string.     Format string in the given <code>style</code>.     Defaults to <code>\"%(message)s\"</code>.</li> <li><code>datefmt</code>:     Type string.     Format string in the given <code>style</code> for the date/time portion.     Defaults to <code>\"%Y-%m-%d %H:%M:%S,uuu\"</code>.</li> <li> <p><code>style</code>:     Determines how the format string will be merged with its data.     Must be one of <code>\"%\", \"{\", \"$\"</code>.</p> </li> <li> <p><code>filters</code>:   Type object.   Filter definitions. Each key is a filter id and each value is a dict describing how to configure the corresponding filter.</p> </li> </ul> <p>The object's values are of type object.   Filter configuration. * <code>handlers</code>:   Type object.   Handler definitions. Each key is a handler id and each value is an object describing how to configure the corresponding handler.</p> <p>The object's values are of type object.   Handler configuration. All keys other than the following are passed through as keyword arguments to the handler's constructor.   The key <code>class</code> is required.</p> <ul> <li><code>class</code>:     Type string.     The fully qualified name of the handler class. See logging handlers.</li> <li><code>level</code>:     The level of the handler.     Must be one of <code>\"CRITICAL\", \"ERROR\", \"WARNING\", \"INFO\", \"DEBUG\", \"NOTSET\"</code>.</li> <li><code>formatter</code>:     Type string.     The id of the formatter for this handler.</li> <li> <p><code>filters</code>:     Type array.     A list of ids of the filters for this logger.</p> <p>The array's items are of type string.</p> </li> <li> <p><code>loggers</code>:   Type object.   Logger definitions. Each key is a logger name and each value is an object describing how to configure the corresponding logger. The tool's logger has the id <code>'zappend'</code>.</p> </li> </ul> <p>The object's values are of type object.   Logger configuration.</p> <ul> <li><code>level</code>:     The level of the logger.     Must be one of <code>\"CRITICAL\", \"ERROR\", \"WARNING\", \"INFO\", \"DEBUG\", \"NOTSET\"</code>.</li> <li><code>propagate</code>:     Type boolean.     The propagation setting of the logger.</li> <li> <p><code>filters</code>:     Type array.     A list of ids of the filters for this logger.</p> <p>The array's items are of type string.   * <code>handlers</code>: Type array. A list of ids of the handlers for this logger.</p> <p>The array's items are of type string.</p> </li> </ul>"},{"location":"guide/","title":"User Guide","text":"<p>Coming soon.</p>"},{"location":"start/","title":"Getting Started","text":""},{"location":"start/#installation","title":"Installation","text":"<pre><code>pip install zappend\n</code></pre>"},{"location":"start/#using-the-cli","title":"Using the CLI","text":"<p>Get usage help:</p> <pre><code>zappend --help\n</code></pre> <p>Get configuration help: </p> <pre><code>zappend --help-config md\n</code></pre> <p>Process list of local slice paths:</p> <pre><code>zappend --target target.zarr slice-1.nc slice-2.nc slice-3.nc\n</code></pre> <p>Process list of local slice paths with configuration in <code>config.yaml</code>:</p> <pre><code>zappend --config config.yaml slice-1.nc slice-2.nc slice-3.nc\n</code></pre>"},{"location":"start/#using-the-python-api","title":"Using the Python API","text":"<p>Process list of local slice paths:</p> <pre><code>from zappend.api import zappend\n\nzappend([\"slice-1.nc\", \"slice-2.nc\", \"slice-3.nc\"], target_dir=\"target.zarr\")\n</code></pre> <p>Process list of local slice paths with configuration:</p> <pre><code>from zappend.api import zappend\n\nconfig = { \"target_dir\": \"target.zarr\" }\n\nzappend([\"slice-1.nc\", \"slice-2.nc\", \"slice-3.nc\"], config=config)\n</code></pre> <p>Process slice paths in S3 with slice generator and configuration:</p> <pre><code>import numpy as np\nimport xarray as xr\nfrom zappend.api import zappend\n\nconfig = { \"target_dir\": \"target.zarr\" }\n\ndef get_mean_time(slice_ds: xr.Dataset) -&gt; xr.DataArray:\n    time = slice_ds.time\n    t0 = time[0]\n    dt = time[-1] - t0\n    return xr.DataArray(np.array([t0 + dt / 2], \n                                 dtype=slice_ds.time.dtype), \n                        dims=\"time\")\n\ndef get_mean_slice(slice_ds: xr.Dataset) -&gt; xr.Dataset: \n    mean_slice_ds = slice_ds.mean(\"time\")\n    mean_slice_ds = mean_slice_ds.expand_dims(\"time\", axis=0)\n    mean_slice_ds.coords[\"time\"] = get_mean_time(slice_ds)\n    return mean_slice_ds \n\ndef get_slices(slice_paths: list[str]):\n    for slice_path in slice_paths:\n        ds = xr.open_dataset(\"s3://mybucket/eodata/\" + slice_path)\n        yield get_mean_slice(ds) \n\nzappend(get_slices([\"slice-1.nc\", \"slice-2.nc\", \"slice-3.nc\"]),\n        config=config)\n</code></pre>"}]}